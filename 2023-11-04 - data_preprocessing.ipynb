{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing \n",
    "\n",
    "The goal to this script is to construct the data pipeline for the music generation AI.\n",
    "- Load the musics;\n",
    "- Split them into sequences of a cetain length\n",
    "- Convert the splits into MEL-spetrograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import tensorflow as tf\n",
    "\n",
    "TESTED_SOUND = \"data/full_sounds\\Electro\\Alex Skrindo - Jumbo [NCS Release].mp3\"\n",
    "FINAL_IMG_FOLDER = \"data/imgs\"\n",
    "BASE_FOLDER = \"data/full_sounds/electro\"\n",
    "SPETROGRAMS_LENGTH = 45 # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(TESTED_SOUND)\n",
    "y = y/np.max(y)\n",
    "f\"Sampling Rate: {sr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(y.shape[0])/sr\n",
    "t.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "plt.plot(t/60, y)\n",
    "plt.xlabel(\"Time in minutes\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqin, seqout = 0*sr, SPETROGRAMS_LENGTH*sr\n",
    "sequence = y[seqin: seqout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_mel_spetrogram = librosa.feature.melspectrogram(y=sequence, sr=sr)\n",
    "S_dB = librosa.power_to_db(sequence_mel_spetrogram, ref=np.max)\n",
    "f\"spetrogram shape: {S_dB.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "ax = plt.subplot(111)\n",
    "pos = plt.imshow(S_dB)\n",
    "plt.colorbar(pos, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectrogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def make_dataset(\n",
    "    base_folder:str=BASE_FOLDER, \n",
    "    save_to:str=FINAL_IMG_FOLDER, \n",
    "    sequence_length:float=SPETROGRAMS_LENGTH,\n",
    "    overlap:float=0.5\n",
    "    ):\n",
    "    \n",
    "    for root, _, files in os.walk(base_folder):        \n",
    "        filtered_files = [f'{root}/{f}' for f in files if '.mp3' in f]      \n",
    "        \n",
    "          \n",
    "        \n",
    "        for f in filtered_files:\n",
    "            basename = os.path.basename(f)\n",
    "            fname = os.path.splitext(basename)[0]\n",
    "            loaded_sound, sr = librosa.load(f)\n",
    "            loaded_sound = loaded_sound/np.max(loaded_sound)\n",
    "            \n",
    "            for i, seqin in enumerate(range(0, int(loaded_sound.shape[0] - SPETROGRAMS_LENGTH*sr), int(SPETROGRAMS_LENGTH*sr*overlap))):\n",
    "                \n",
    "                print(f'\\r{i} {fname}', end=\"\")\n",
    "                seqout = seqin + SPETROGRAMS_LENGTH*sr\n",
    "                \n",
    "                selected_sequence = loaded_sound[seqin:seqout]\n",
    "                \n",
    "                sequence_mel_spetrogram = librosa.feature.melspectrogram(y=selected_sequence, sr=sr)\n",
    "                S_dB = librosa.power_to_db(sequence_mel_spetrogram, ref=np.max)\n",
    "                tensor_S_dB = tf.convert_to_tensor(S_dB)\n",
    "                \n",
    "                encoded_S_dB = tf.io.serialize_tensor(tensor_S_dB)\n",
    "                \n",
    "                features = {\n",
    "                    \"max\":np.max(S_dB),\n",
    "                    \"min\":np.min(S_dB),\n",
    "                    \"filename\":fname,\n",
    "                    \"n_chunk\":i,\n",
    "                    \"raw_image\":encoded_S_dB\n",
    "                }\n",
    "                break\n",
    "            break\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
